{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         protein_sequence   pH    tm\n",
       "seq_id                                                              \n",
       "0       AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0  75.7\n",
       "1       AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0  50.5\n",
       "2       AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0  40.5\n",
       "3       AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0  47.2\n",
       "4       AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0  49.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load training data (will be put in a function later)  \n",
    "path = os.getcwd()\n",
    "for i in range(3) :\n",
    "\n",
    "    path = os.path.dirname(path)\n",
    "\n",
    "path += '/data/'\n",
    "train_df = pd.read_csv(path + 'train_v1.csv',index_col=\"seq_id\")\n",
    "train_df = train_df.drop(columns=['data_source'])\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('train_v1copy.csv' ,index_col=\"seq_id\")\n",
    "# train_df = train_df.drop(['data_source'], axis=1)\n",
    "# len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         protein_sequence   pH  length\n",
      "seq_id                                                                \n",
      "0       AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0     341\n",
      "1       AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0     286\n",
      "2       AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0     497\n",
      "3       AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0     265\n",
      "4       AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0    1451\n",
      "...                                                   ...  ...     ...\n",
      "31385   YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0     549\n",
      "31386   YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0     469\n",
      "31387   YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0     128\n",
      "31388   YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0     593\n",
      "31389   YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0     537\n",
      "\n",
      "[28695 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df['length'] = train_df['protein_sequence'].str.len()\n",
    "train_df['length'].value_counts()\n",
    "train_df['length'].nunique()\n",
    "#print(train_df)\n",
    "train_df_without_tm = train_df.copy()\n",
    "del train_df_without_tm['tm']\n",
    "print(train_df_without_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df,tm,ratio):\n",
    "    num_row = len(df)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[:index_split]\n",
    "    index_te = indices[index_split:]\n",
    "\n",
    "    x_tr = df.iloc[index_tr]\n",
    "    x_te = df.iloc[index_te]\n",
    "    y_tr = tm.iloc[index_tr]\n",
    "    y_te = tm.iloc[index_te]\n",
    "    \n",
    "    return y_tr, x_tr, y_te, x_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scoring(df_te, df_predicted):\n",
    "    df = {\n",
    "    \"true\": df_te['tm'],\n",
    "    \"predicted\": df_predicted['tm']\n",
    "}\n",
    "    pearson = df.corr(method='pearson')\n",
    "    rmse = mean_squared_error(df_te['tm'], df_predicted['tm'], squared=False)\n",
    "    auc = metrics.roc_auc_score(df_te['tm'], df_predicted['tm'])\n",
    "    \n",
    "    print('Pearson: %.3f, RMSE %.3f, AUC: %.3f' %(pearson, rmse, auc))\n",
    "    return pearson, rmse, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, x_tr, y_te, x_te = split_data(train_df_without_tm, train_df['tm'],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 12 11:39:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8    12W / 235W |   7875MiB /  7982MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1204      G   /usr/lib/xorg/Xorg                 16MiB |\n",
      "|    0   N/A  N/A    831044      C   ...maid/anaconda3/bin/python      725MiB |\n",
      "|    0   N/A  N/A    832430      C   ...ence/anaconda3/bin/python     7129MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "/usr/bin/nvcc\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V && which nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: \\ ^C\n",
      "- "
     ]
    }
   ],
   "source": [
    "!conda install -c rapidsai -c nvidia -c conda-forge -c defaults rapidsai::rapids python=3.7 cudatoolkit=10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../rapids.0.13.0': No such file or directory\n",
      "/bin/bash: line 0: cd: /opt/conda/envs/: No such file or directory\n",
      "cp: cannot stat '/opt/conda/envs/rapids/lib/libxgboost.so': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!cp ../rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_833812/2572053987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#if torch.cuda.is_available():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print('RAPIDS version',cuda.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "\n",
    "#if torch.cuda.is_available():  \n",
    "#print('RAPIDS version',cuda.__version__)\n",
    "\n",
    "print('Train shape:', train_df.shape )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164     748\n",
      "231     318\n",
      "455     245\n",
      "155     243\n",
      "148     241\n",
      "       ... \n",
      "1366      1\n",
      "1690      1\n",
      "2069      1\n",
      "1872      1\n",
      "1345      1\n",
      "Name: length, Length: 1962, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "vc = train_df.length.value_counts()\n",
    "print(vc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find minimum number operations to convert str1 to str2 (FROM GEEKSFORGEEKS)\n",
    "# \n",
    "def edit_distance(str1, str2):\n",
    "\tm = len(str1)\n",
    "\tn = len(str2)\n",
    "\n",
    "\t# Create a table to store results of subproblems\n",
    "\tdp = [[0 for x in range(n + 1)] for x in range(m + 1)]\n",
    "\n",
    "\t# Fill d[][] in bottom up manner\n",
    "\tfor i in range(m + 1):\n",
    "\t\tfor j in range(n + 1):\n",
    "\n",
    "\t\t\t# If first string is empty, only option is to\n",
    "\t\t\t# insert all characters of second string\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tdp[i][j] = j    # Min. operations = j\n",
    "\n",
    "\t\t\t# If second string is empty, only option is to\n",
    "\t\t\t# remove all characters of second string\n",
    "\t\t\telif j == 0:\n",
    "\t\t\t\tdp[i][j] = i    # Min. operations = i\n",
    "\n",
    "\t\t\t# If last characters are same, ignore last char\n",
    "\t\t\t# and recur for remaining string\n",
    "\t\t\telif str1[i-1] == str2[j-1]:\n",
    "\t\t\t\tdp[i][j] = dp[i-1][j-1]\n",
    " \n",
    "            # If last character are different, consider all\n",
    "            # possibilities and find minimum\n",
    "\t\t\telse:\n",
    "\t\t\t\tdp[i][j] = 1 + min(dp[i][j-1],        # Insert,\n",
    "\t\t\t\t\t\t\t\tdp[i-1][j],        # Remove\n",
    "\t\t\t\t\t\t\t\tdp[i-1][j-1])    # Replace\n",
    " \n",
    "\treturn dp[m][n]\n",
    " \n",
    " \n",
    "\n",
    "# This code is contributed by Bhavya Jain\n",
    "\n",
    "\n",
    "print(len(train_df.protein_sequence[65]), len(train_df.protein_sequence[128]))\n",
    "\n",
    "# str1 = train_df.protein_sequence[578]\n",
    "# str2 = train_df.protein_sequence[579]\t\n",
    "\n",
    "str1 = train_df.protein_sequence[65]\n",
    "str2 = train_df.protein_sequence[128]\n",
    "\n",
    "edit_distance(str1, str2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance_matrix(df):\n",
    "    vlign = []\n",
    "    for id in df.index:\n",
    "        \n",
    "        hlign = []\n",
    "        for jd in df.index:\n",
    "            hlign.append(edit_distance(df[id], df[jd]))\n",
    "        vlign.append(hlign)\n",
    "        \n",
    "    sums = vlign.copy()\n",
    "    sums = np.sum(sums, axis=1)\n",
    "    wildtype = np.argmin(sums)\n",
    "    return vlign \n",
    "\n",
    " #edit_distance_matrix(tmp[:50]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                 | 0/1962 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#import cuDF\n",
    "train_df['group'] = -1\n",
    "train_df['type'] = 'unknown'\n",
    "\n",
    "grp = 0\n",
    "wildtype_ids = []\n",
    "\n",
    "# MUTATION THRESHOLD\n",
    "M_THRESHOLD = 10\n",
    "# INSERTION DELETION THRESHOLD\n",
    "D_THRESHOLD = 3\n",
    "\n",
    "for k in tqdm(range(0, len(vc))): \n",
    "    c = vc.index[k]\n",
    "    # SUBSET OF TRAIN DATA WITH SAME PROTEIN LENGTH PLUS MINUS D_THRESHOLD\n",
    "    tmp = train_df.loc[(train_df.length>=c-D_THRESHOLD)&(train_df.length<=c+D_THRESHOLD)&(train_df.group==-1)]\n",
    "    if len(tmp)<=1: break\n",
    "    \n",
    "    # COMPUTE LEVENSTEIN DISTANCE\n",
    "    #x = tmp.protein_sequence.str.edit_distance_matrix() #original but cudf is needed\n",
    "    x = edit_distance_matrix(tmp['protein_sequence']) #fonction fait maison \n",
    "    x = np.array( pd.Series(x).values.tolist() )\n",
    "    #wildtype_ids.append(wt)\n",
    "    #train_df.loc[wt,'type'] = 'WT'\n",
    "    \n",
    "    # COUNT HOW MANY MUTATIONS WE SEE\n",
    "    mutation = []\n",
    "    for kk in range(1,M_THRESHOLD+1):\n",
    "        mutation.append( len( np.unique( np.where( x==kk )[0] ) ) )\n",
    "        \n",
    "    # FIND RELATED ROWS IN TRAIN WITH M_THRESHOLD MUTATIONS OR LESS\n",
    "    y = np.unique( np.where( (x>0)&(x<=M_THRESHOLD) )[0] )\n",
    "    seen = []\n",
    "    for j in y:\n",
    "        if j in seen: continue\n",
    "        i = np.where( np.array(x[j,])<=M_THRESHOLD )[0]\n",
    "        seen += list(i)\n",
    "        idx = tmp.iloc[i,].index \n",
    "        train_df.loc[idx,'group'] = grp\n",
    "        grp += 1\n",
    "    ct = vc.iloc[k]\n",
    "    ct2 = len(tmp)\n",
    "    print(f'k={k} len={c} ct={ct} ct2={ct2} dist_ct={mutation}') \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting proteins without groups\n",
    "train_df_groups = train_df[train_df.group!= -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving train_df in CSV file \n",
    "train_df_more_columns= train_df_groups.copy()\n",
    "train_df_more_columns.to_csv('train_df_more_columns.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display code\n",
    "for k in range(10):\n",
    "    print('#'*25)\n",
    "    print(f'### GROUP {k}')\n",
    "    print('#'*25)\n",
    "    display( train_df.loc[train_df.group==k] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum number operations to convert str1 to str2\n",
    "\n",
    " \n",
    "def editDistDP(str1, str2, m, n):\n",
    "    dp = [[0 for x in range(n + 1)] for x in range(m + 1)]\n",
    " \n",
    "    # Fill d[][] in bottom up manner\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    " \n",
    "            # If first string is empty, only option is to\n",
    "            # insert all characters of second string\n",
    "            if i == 0:\n",
    "                dp[i][j] = j    # Min. operations = j\n",
    " \n",
    "            # If second string is empty, only option is to\n",
    "            # remove all characters of second string\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i    # Min. operations = i\n",
    " \n",
    "            # If last characters are same, ignore last char\n",
    "            # and recur for remaining string\n",
    "            elif str1[i-1] == str2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    " \n",
    "            # If last character are different, consider all\n",
    "            # possibilities and find minimum\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j-1],        # Insert\n",
    "                                   dp[i-1][j],        # Remove\n",
    "                                   dp[i-1][j-1])    # Replace\n",
    " \n",
    "    return dp[m][n]\n",
    " \n",
    " \n",
    "# Driver code\n",
    "str1 = train_df['protein_sequence'][0]\n",
    "str2 = train_df['protein_sequence'][1]\n",
    " \n",
    "print(editDistDP(str1, str2, len(str1), len(str2)))\n",
    "# This code is contributed by Bhavya Jain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = train_df.loc[train_df.group==-1].shape[0] \n",
    "mx = train_df.group.max() \n",
    "train_df.loc[train_df.group==-1,'group'] = np.arange(nrow) + mx + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a401f25d14e4726c47ec3d51a0ef0f076129e7cc070ddb98f69a4ab74ec023d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
