{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DupCLlNQ5z-A"
   },
   "source": [
    "# Language model :ProtBert  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Note :This notebook was ran on google colab \n",
    "\n",
    "submission in folder under the name `submission_prot.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24362,
     "status": "ok",
     "timestamp": 1671716142517,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "_Dc_icJr51ls",
    "outputId": "7750a895-2779-4cfe-9e79-377ef149fd3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20997,
     "status": "ok",
     "timestamp": 1671716163509,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "BDagHWuT5z-E"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import rankdata\n",
    "import os\n",
    "os.system('pip install tokenizers')\n",
    "os.system('pip install transformers')\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPNqhuYz5z-G"
   },
   "source": [
    "Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1671716163509,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "OXUPk-Mv5z-G"
   },
   "outputs": [],
   "source": [
    "MODEL = 'Rostlab/prot_bert'\n",
    "SAVE_PATH = '/content/drive/MyDrive/ml/data/'\n",
    "\n",
    "MAX_LEN = 512 # protein sequence max length \n",
    "BATCH_SIZE = 6\n",
    "VER =1 # version of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_ofWMGI5z-G"
   },
   "source": [
    "1. Load the dataset  lean_train_data.csv (from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2858,
     "status": "ok",
     "timestamp": 1671716166359,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "hHvwKMDL5z-H"
   },
   "outputs": [],
   "source": [
    "\n",
    "#### put in function ####\n",
    "path = '/content/drive/MyDrive/ml/data/'\n",
    "\n",
    "train = pd.read_csv(path+'clean_train_data.csv')\n",
    "train = train.drop(columns=['operation','position2','change1','change2','pH2','group2','data_source1','data_source2'])\n",
    "train = train.rename(columns={\"position1\": \"position\"})\n",
    "\n",
    "test = pd.read_csv(path+'test_mutations.csv')\n",
    "submission = pd.read_csv(path+'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671711817420,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "1gFMlTbk5z-H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1671716166359,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "EpztCVEf5z-H"
   },
   "outputs": [],
   "source": [
    "# test wildtype sequence (original sequence)\n",
    "test_wildtype = 'VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQRVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGTNAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKALGSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK'\n",
    "\n",
    "# add to dataframe\n",
    "test['protSeq1'] = test_wildtype\n",
    "\n",
    "#rename columns to match train\n",
    "test = test.rename(columns = {'protein_sequence':'protSeq2','modif':'position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1671716166360,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "j6MAtZev5z-I"
   },
   "outputs": [],
   "source": [
    "# add spaces betwwen Amnino acids letter to tokenize\n",
    "def add_spaces(x):\n",
    "    return \" \".join(list(x))\n",
    "\n",
    "\n",
    "train.protSeq1 = train.protSeq1.map(add_spaces)\n",
    "train.protSeq2 = train.protSeq2.map(add_spaces)\n",
    "\n",
    "test.protSeq1 = test.protSeq1.map(add_spaces)\n",
    "test.protSeq2 = test.protSeq2.map(add_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf5R-av5z-I"
   },
   "source": [
    "As mentioned in the report, we rank normalize the train data **dtm** for each group that have the same wildtype and different mutations. We saw a significant increase in the spearman correlation coefficient on test set as the model is trying to learn ranking of mutations for each group rather than just the mutation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1671716166360,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "tW1P2IRX5z-J"
   },
   "outputs": [],
   "source": [
    "# rank normalize the dTm for each group of mutations \n",
    "for p in train.group1.unique():\n",
    "    target = 'target'\n",
    "    train.loc[train.group1==p,'target'] =\\\n",
    "        rankdata( train.loc[train.group1==p,target] )/len( train.loc[train.group1==p,target] )\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1671716166360,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "DScV0Tuj5z-J"
   },
   "outputs": [],
   "source": [
    "# reset index (to pass to dataset)\n",
    "train = train.reset_index(drop=True)\n",
    "test  = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1671677464733,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "GWusB8qS5z-J",
    "outputId": "776935be-5db3-4147-eb82-096df2acb47c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/ml/data/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/ml/data/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/ml/data/vocab.txt',\n",
       " '/content/drive/MyDrive/ml/data/added_tokens.json',\n",
       " '/content/drive/MyDrive/ml/data/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained Protbert tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.save_pretrained(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1671677464734,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "GbZSRL-H5z-K",
    "outputId": "f682c53e-bbb4-45b7-8b81-ddb0f18bea6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-de658e90-a045-4dfa-a0d0-f0cb8f15bd09\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protSeq1</th>\n",
       "      <th>protSeq2</th>\n",
       "      <th>position</th>\n",
       "      <th>pH1</th>\n",
       "      <th>tm1</th>\n",
       "      <th>group1</th>\n",
       "      <th>tm2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M N A F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>M N D F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>62.9</td>\n",
       "      <td>5</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.043605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M N A F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>M N E F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>62.9</td>\n",
       "      <td>5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.136628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M N A F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>M N F F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>62.9</td>\n",
       "      <td>5</td>\n",
       "      <td>61.7</td>\n",
       "      <td>0.380814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M N A F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>M N G F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>62.9</td>\n",
       "      <td>5</td>\n",
       "      <td>58.9</td>\n",
       "      <td>0.127907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M N A F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>M N L F E M L R I D E R L R L K I Y K D T E G ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>62.9</td>\n",
       "      <td>5</td>\n",
       "      <td>65.6</td>\n",
       "      <td>0.741279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>57</td>\n",
       "      <td>65.5</td>\n",
       "      <td>0.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>57</td>\n",
       "      <td>78.8</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.8</td>\n",
       "      <td>57</td>\n",
       "      <td>71.2</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.8</td>\n",
       "      <td>57</td>\n",
       "      <td>65.5</td>\n",
       "      <td>0.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>M G C V Q C K D K E A T K L T E E R D G S L N ...</td>\n",
       "      <td>86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.8</td>\n",
       "      <td>57</td>\n",
       "      <td>52.9</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296 rows Ã— 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de658e90-a045-4dfa-a0d0-f0cb8f15bd09')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-de658e90-a045-4dfa-a0d0-f0cb8f15bd09 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-de658e90-a045-4dfa-a0d0-f0cb8f15bd09');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               protSeq1  \\\n",
       "0     M N A F E M L R I D E R L R L K I Y K D T E G ...   \n",
       "1     M N A F E M L R I D E R L R L K I Y K D T E G ...   \n",
       "2     M N A F E M L R I D E R L R L K I Y K D T E G ...   \n",
       "3     M N A F E M L R I D E R L R L K I Y K D T E G ...   \n",
       "4     M N A F E M L R I D E R L R L K I Y K D T E G ...   \n",
       "...                                                 ...   \n",
       "2291  M G C V Q C K D K E A T K L T E E R D G S L N ...   \n",
       "2292  M G C V Q C K D K E A T K L T E E R D G S L N ...   \n",
       "2293  M G C V Q C K D K E A T K L T E E R D G S L N ...   \n",
       "2294  M G C V Q C K D K E A T K L T E E R D G S L N ...   \n",
       "2295  M G C V Q C K D K E A T K L T E E R D G S L N ...   \n",
       "\n",
       "                                               protSeq2  position  pH1   tm1  \\\n",
       "0     M N D F E M L R I D E R L R L K I Y K D T E G ...         2  6.5  62.9   \n",
       "1     M N E F E M L R I D E R L R L K I Y K D T E G ...         2  6.5  62.9   \n",
       "2     M N F F E M L R I D E R L R L K I Y K D T E G ...         2  6.5  62.9   \n",
       "3     M N G F E M L R I D E R L R L K I Y K D T E G ...         2  6.5  62.9   \n",
       "4     M N L F E M L R I D E R L R L K I Y K D T E G ...         2  6.5  62.9   \n",
       "...                                                 ...       ...  ...   ...   \n",
       "2291  M G C V Q C K D K E A T K L T E E R D G S L N ...        86  8.0  52.9   \n",
       "2292  M G C V Q C K D K E A T K L T E E R D G S L N ...        86  8.0  52.9   \n",
       "2293  M G C V Q C K D K E A T K L T E E R D G S L N ...        86  8.0  78.8   \n",
       "2294  M G C V Q C K D K E A T K L T E E R D G S L N ...        86  8.0  78.8   \n",
       "2295  M G C V Q C K D K E A T K L T E E R D G S L N ...        86  8.0  78.8   \n",
       "\n",
       "      group1   tm2    target  \n",
       "0          5  56.2  0.043605  \n",
       "1          5  59.0  0.136628  \n",
       "2          5  61.7  0.380814  \n",
       "3          5  58.9  0.127907  \n",
       "4          5  65.6  0.741279  \n",
       "...      ...   ...       ...  \n",
       "2291      57  65.5  0.794000  \n",
       "2292      57  78.8  0.944000  \n",
       "2293      57  71.2  0.330000  \n",
       "2294      57  65.5  0.199000  \n",
       "2295      57  52.9  0.058000  \n",
       "\n",
       "[2296 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1671716166361,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "71eXB3XN5z-K"
   },
   "outputs": [],
   "source": [
    "def prepare_input(tokenizer, text):\n",
    "    # tokenize text (add special tokens and pad/truncate to max length)\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=MAX_LEN,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class MutationDataset(Dataset):\n",
    "    def __init__(self,tokenizer, df):\n",
    "        self.tokenizer = tokenizer\n",
    "       \n",
    "        self.inputs1 = df['protSeq1'].values\n",
    "        self.inputs2 = df['protSeq2'].values\n",
    "        self.position = df['position'].values\n",
    "        self.labels = df['target'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        #tokenize input texts\n",
    "        inputs1 = prepare_input(self.tokenizer, self.inputs1[item])\n",
    "        inputs2 = prepare_input(self.tokenizer, self.inputs2[item])\n",
    "        \n",
    "        # do one hot encoding of position \n",
    "        position = np.zeros(MAX_LEN)\n",
    "        position[self.position[item]] = 1\n",
    "\n",
    "        position = torch.tensor(position, dtype=torch.int8)\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "       \n",
    "        return inputs1, inputs2, position, label \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1671716166361,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "dljpOOkp5z-K"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        # expandig the attention mask to match the shape of the hidden states\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "\n",
    "        #averaging the embeddings\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class ProtBertStab(nn.Module):\n",
    "    def __init__(self, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "       \n",
    "        # for model loading\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
    "        else:\n",
    "            # for model inference\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            # load pretrained model\n",
    "            self.model = AutoModel.from_pretrained(MODEL, config=self.config)\n",
    "        else:\n",
    "            # load model from config\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "      \n",
    "\n",
    "\n",
    "        self.pool = MeanPooling() # for mean pooling\n",
    "\n",
    "         # modify last layer \n",
    "        self.lin = nn.Linear(self.config.hidden_size,64)\n",
    "\n",
    "        # add layer to predict dTm\n",
    "        self.fc = nn.Linear(64*3,1)\n",
    "            \n",
    "        \n",
    "         \n",
    "            \n",
    "            \n",
    "       \n",
    "        \n",
    "    def feature(self, inputs,position):\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        \n",
    "        feature = self.pool(last_hidden_states, position)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs1,inputs2,position):\n",
    "        #get embedding from model \n",
    "        feature1 = self.lin(self.feature(inputs1,inputs1['attention_mask']))\n",
    "        feature2 = self.lin(self.feature(inputs2,inputs2['attention_mask']))\n",
    "       \n",
    "        # create 4  channel tensor with the 4 embeddings\n",
    "        feature = torch.concat((feature1, feature2, feature2 - feature1),axis=1)\n",
    "        #concatenate all the features with the difference between each two features (we study the difference in melting point)\n",
    "       \n",
    "\n",
    "        output = self.fc(feature)\n",
    "        \n",
    "\n",
    "        \n",
    "  \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1671716166361,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "B_riM8xO5z-L"
   },
   "outputs": [],
   "source": [
    "# Both from internet\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, reduction='mean', eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
    "        if self.reduction == 'none':\n",
    "            loss = loss\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if val == np.nan:\n",
    "          return\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYZRTXS65z-L"
   },
   "source": [
    "Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1671677465161,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "avcZv8a35z-L"
   },
   "outputs": [],
   "source": [
    "#import KFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671716174420,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "35oUAikT5z-L"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1671677465162,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "GXD9LI8B7i7r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1671716171395,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "sDi4TFPg5z-M"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_loader, epoch):\n",
    "    model.train()\n",
    "    rho = AverageMeter()\n",
    "    train_loss = AverageMeter() \n",
    "   \n",
    "    for batch_idx, (inputs1, inputs2, position, target ) in enumerate(train_loader):\n",
    "        # inputs to device\n",
    "        for k, v in inputs1.items():\n",
    "            inputs1[k] = v.to(device)     \n",
    "        for k, v in inputs2.items():\n",
    "            inputs2[k] = v.to(device)\n",
    "        position = position.to(device)\n",
    "        target = target.to(device)\n",
    "       \n",
    "        #batch_size = target.size(0)\n",
    "\n",
    "        \n",
    "        output = model(inputs1,inputs2,position)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        train_loss.update(loss.item(), target.shape[0])\n",
    "        rho.update(spearmanr(target.cpu().detach().numpy(), output.cpu().detach().numpy()).correlation, target.shape[0])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * target.shape[0]}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {train_loss.avg:.6f} \\t spearman: {rho.avg:.6f}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(   f\"Train Epoch: {epoch} \" f\" loss={train_loss.avg:0.2e} \" f\" rho={rho.avg:0.2f} \" )\n",
    "    return train_loss.avg , rho.avg\n",
    "\n",
    "\n",
    "def test_epoch(model, criterion, test_loader):\n",
    "    model = model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    rho = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs1, inputs2, position, target ) in enumerate(test_loader):\n",
    "            # inputs to device\n",
    "            for k, v in inputs1.items():\n",
    "                inputs1[k] = v.to(device)     \n",
    "            for k, v in inputs2.items():\n",
    "                inputs2[k] = v.to(device)\n",
    "            position = position.to(device)\n",
    "            target = target.to(device)\n",
    "           \n",
    "          \n",
    "            # predict\n",
    "            output = model(inputs1,inputs2,position)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss.update(loss.item(), target.shape[0])\n",
    "            rho.update(spearmanr(target.cpu().detach().numpy(), output.cpu().detach().numpy()).correlation,target.shape[0])\n",
    "          \n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Test Epoch: [{batch_idx * target.shape[0]}/{len(test_loader.dataset)} ({100. * batch_idx / len(test_loader):.0f}%)]\\tLoss: {test_loss.avg:.6f} \\t spearman: {rho.avg:.6f}\")\n",
    "            \n",
    "\n",
    "    print(   f\"Test Epoch: \" f\" loss={test_loss.avg:0.2e} \" f\" rho={rho.avg:0.2f} \" )\n",
    "\n",
    "    return test_loss.avg ,rho.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3229496,
     "status": "ok",
     "timestamp": 1671680694653,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "mzTPwL2U5z-M",
    "outputId": "799fbdac-6399-4b6c-f512-090cf52fa34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2296 (0%)]\tLoss: 0.339859 \t spearman: -0.485714\n",
      "Train Epoch: 1 [30/2296 (3%)]\tLoss: 0.503134 \t spearman: -0.010238\n",
      "Train Epoch: 1 [60/2296 (7%)]\tLoss: 0.417750 \t spearman: -0.001361\n",
      "Train Epoch: 1 [90/2296 (10%)]\tLoss: 0.391066 \t spearman: 0.063594\n",
      "Train Epoch: 1 [120/2296 (13%)]\tLoss: 0.358406 \t spearman: 0.082927\n",
      "Train Epoch: 1 [150/2296 (16%)]\tLoss: 0.336285 \t spearman: 0.081232\n",
      "Train Epoch: 1 [180/2296 (20%)]\tLoss: 0.316753 \t spearman: 0.092272\n",
      "Train Epoch: 1 [210/2296 (23%)]\tLoss: 0.307072 \t spearman: 0.097787\n",
      "Train Epoch: 1 [240/2296 (26%)]\tLoss: 0.301294 \t spearman: 0.089947\n",
      "Train Epoch: 1 [270/2296 (29%)]\tLoss: 0.294091 \t spearman: 0.099529\n",
      "Train Epoch: 1 [300/2296 (33%)]\tLoss: 0.290610 \t spearman: 0.100990\n",
      "Train Epoch: 1 [330/2296 (36%)]\tLoss: 0.285515 \t spearman: 0.077477\n",
      "Train Epoch: 1 [360/2296 (39%)]\tLoss: 0.286886 \t spearman: 0.069185\n",
      "Train Epoch: 1 [390/2296 (42%)]\tLoss: 0.284104 \t spearman: 0.075249\n",
      "Train Epoch: 1 [420/2296 (46%)]\tLoss: 0.283799 \t spearman: 0.055859\n",
      "Train Epoch: 1 [450/2296 (49%)]\tLoss: 0.283330 \t spearman: 0.053412\n",
      "Train Epoch: 1 [480/2296 (52%)]\tLoss: 0.281943 \t spearman: 0.044891\n",
      "Train Epoch: 1 [510/2296 (56%)]\tLoss: 0.283060 \t spearman: 0.033578\n",
      "Train Epoch: 1 [540/2296 (59%)]\tLoss: 0.282377 \t spearman: 0.028998\n",
      "Train Epoch: 1 [570/2296 (62%)]\tLoss: 0.281856 \t spearman: 0.037775\n",
      "Train Epoch: 1 [600/2296 (65%)]\tLoss: 0.280143 \t spearman: 0.049542\n",
      "Train Epoch: 1 [630/2296 (69%)]\tLoss: 0.279675 \t spearman: 0.050444\n",
      "Train Epoch: 1 [660/2296 (72%)]\tLoss: 0.279806 \t spearman: 0.058762\n",
      "Train Epoch: 1 [690/2296 (75%)]\tLoss: 0.279336 \t spearman: 0.067874\n",
      "Train Epoch: 1 [720/2296 (78%)]\tLoss: 0.280139 \t spearman: 0.065891\n",
      "Train Epoch: 1 [750/2296 (82%)]\tLoss: 0.280454 \t spearman: 0.067352\n",
      "Train Epoch: 1 [780/2296 (85%)]\tLoss: 0.278600 \t spearman: 0.067602\n",
      "Train Epoch: 1 [810/2296 (88%)]\tLoss: 0.277598 \t spearman: 0.069324\n",
      "Train Epoch: 1 [840/2296 (92%)]\tLoss: 0.276415 \t spearman: 0.065293\n",
      "Train Epoch: 1 [870/2296 (95%)]\tLoss: 0.277072 \t spearman: 0.063038\n",
      "Train Epoch: 1 [900/2296 (98%)]\tLoss: 0.278741 \t spearman: 0.063489\n",
      "Train Epoch: 1  loss=2.79e-01  rho=0.06 \n",
      "Test Epoch: [0/2296 (0%)]\tLoss: 0.288564 \t spearman: -0.257143\n",
      "Test Epoch: [30/2296 (13%)]\tLoss: 0.308680 \t spearman: -0.075325\n",
      "Test Epoch: [60/2296 (26%)]\tLoss: 0.305335 \t spearman: 0.056299\n",
      "Test Epoch: [90/2296 (39%)]\tLoss: 0.299259 \t spearman: -0.031908\n",
      "Test Epoch: [120/2296 (52%)]\tLoss: 0.293765 \t spearman: -0.068313\n",
      "Test Epoch: [150/2296 (65%)]\tLoss: 0.299883 \t spearman: -0.040847\n",
      "Test Epoch: [180/2296 (78%)]\tLoss: 0.302643 \t spearman: -0.039125\n",
      "Test Epoch: [210/2296 (91%)]\tLoss: 0.305449 \t spearman: -0.036029\n",
      "Test Epoch:  loss=3.06e-01  rho=-0.02 \n",
      "Train Epoch: 2 [0/2296 (0%)]\tLoss: 0.497317 \t spearman: -0.085714\n",
      "Train Epoch: 2 [30/2296 (3%)]\tLoss: 0.309766 \t spearman: -0.092767\n",
      "Train Epoch: 2 [60/2296 (7%)]\tLoss: 0.308106 \t spearman: 0.012446\n",
      "Train Epoch: 2 [90/2296 (10%)]\tLoss: 0.288899 \t spearman: -0.105949\n",
      "Train Epoch: 2 [120/2296 (13%)]\tLoss: 0.277212 \t spearman: -0.099761\n",
      "Train Epoch: 2 [150/2296 (16%)]\tLoss: 0.272107 \t spearman: -0.099222\n",
      "Train Epoch: 2 [180/2296 (20%)]\tLoss: 0.273095 \t spearman: -0.073566\n",
      "Train Epoch: 2 [210/2296 (23%)]\tLoss: 0.274374 \t spearman: -0.067534\n",
      "Train Epoch: 2 [240/2296 (26%)]\tLoss: 0.272458 \t spearman: -0.069593\n",
      "Train Epoch: 2 [270/2296 (29%)]\tLoss: 0.274655 \t spearman: -0.066969\n",
      "Train Epoch: 2 [300/2296 (33%)]\tLoss: 0.279203 \t spearman: -0.067761\n",
      "Train Epoch: 2 [330/2296 (36%)]\tLoss: 0.280503 \t spearman: -0.065949\n",
      "Train Epoch: 2 [360/2296 (39%)]\tLoss: 0.280567 \t spearman: -0.068600\n",
      "Train Epoch: 2 [390/2296 (42%)]\tLoss: 0.279748 \t spearman: -0.076054\n",
      "Train Epoch: 2 [420/2296 (46%)]\tLoss: 0.278087 \t spearman: -0.065160\n",
      "Train Epoch: 2 [450/2296 (49%)]\tLoss: 0.276592 \t spearman: -0.060789\n",
      "Train Epoch: 2 [480/2296 (52%)]\tLoss: 0.274295 \t spearman: -0.048960\n",
      "Train Epoch: 2 [510/2296 (56%)]\tLoss: 0.275984 \t spearman: -0.058831\n",
      "Train Epoch: 2 [540/2296 (59%)]\tLoss: 0.276696 \t spearman: -0.044538\n",
      "Train Epoch: 2 [570/2296 (62%)]\tLoss: 0.278015 \t spearman: -0.043607\n",
      "Train Epoch: 2 [600/2296 (65%)]\tLoss: 0.281775 \t spearman: -0.044357\n",
      "Train Epoch: 2 [630/2296 (69%)]\tLoss: 0.284153 \t spearman: -0.048228\n",
      "Train Epoch: 2 [660/2296 (72%)]\tLoss: 0.287438 \t spearman: -0.054340\n",
      "Train Epoch: 2 [690/2296 (75%)]\tLoss: 0.286888 \t spearman: -0.060167\n",
      "Train Epoch: 2 [720/2296 (78%)]\tLoss: 0.285994 \t spearman: -0.059602\n",
      "Train Epoch: 2 [750/2296 (82%)]\tLoss: 0.285895 \t spearman: -0.059196\n",
      "Train Epoch: 2 [780/2296 (85%)]\tLoss: 0.284700 \t spearman: -0.063429\n",
      "Train Epoch: 2 [810/2296 (88%)]\tLoss: 0.284349 \t spearman: -0.055811\n",
      "Train Epoch: 2 [840/2296 (92%)]\tLoss: 0.283454 \t spearman: -0.054762\n",
      "Train Epoch: 2 [870/2296 (95%)]\tLoss: 0.283236 \t spearman: -0.048953\n",
      "Train Epoch: 2 [900/2296 (98%)]\tLoss: 0.283471 \t spearman: -0.040291\n",
      "Train Epoch: 2  loss=2.84e-01  rho=-0.04 \n",
      "Test Epoch: [0/2296 (0%)]\tLoss: 0.317591 \t spearman: 0.028571\n",
      "Test Epoch: [30/2296 (13%)]\tLoss: 0.314661 \t spearman: 0.061030\n",
      "Test Epoch: [60/2296 (26%)]\tLoss: 0.297570 \t spearman: 0.035930\n",
      "Test Epoch: [90/2296 (39%)]\tLoss: 0.305313 \t spearman: 0.006775\n",
      "Test Epoch: [120/2296 (52%)]\tLoss: 0.308023 \t spearman: -0.007421\n",
      "Test Epoch: [150/2296 (65%)]\tLoss: 0.308153 \t spearman: 0.008502\n",
      "Test Epoch: [180/2296 (78%)]\tLoss: 0.300826 \t spearman: 0.029450\n",
      "Test Epoch: [210/2296 (91%)]\tLoss: 0.293016 \t spearman: 0.038074\n",
      "Test Epoch:  loss=2.98e-01  rho=0.04 \n",
      "Train Epoch: 3 [0/2296 (0%)]\tLoss: 0.295316 \t spearman: 0.428571\n",
      "Train Epoch: 3 [30/2296 (3%)]\tLoss: 0.265598 \t spearman: 0.025254\n",
      "Train Epoch: 3 [60/2296 (7%)]\tLoss: 0.311967 \t spearman: -0.052078\n",
      "Train Epoch: 3 [90/2296 (10%)]\tLoss: 0.307593 \t spearman: 0.082203\n",
      "Train Epoch: 3 [120/2296 (13%)]\tLoss: 0.313050 \t spearman: 0.109026\n",
      "Train Epoch: 3 [150/2296 (16%)]\tLoss: 0.319248 \t spearman: 0.073741\n",
      "Train Epoch: 3 [180/2296 (20%)]\tLoss: 0.320516 \t spearman: 0.049033\n",
      "Train Epoch: 3 [210/2296 (23%)]\tLoss: 0.320607 \t spearman: 0.059277\n",
      "Train Epoch: 3 [240/2296 (26%)]\tLoss: 0.310965 \t spearman: 0.021806\n",
      "Train Epoch: 3 [270/2296 (29%)]\tLoss: 0.302868 \t spearman: 0.045910\n",
      "Train Epoch: 3 [300/2296 (33%)]\tLoss: 0.296255 \t spearman: 0.046021\n",
      "Train Epoch: 3 [330/2296 (36%)]\tLoss: 0.289612 \t spearman: 0.031448\n",
      "Train Epoch: 3 [360/2296 (39%)]\tLoss: 0.286629 \t spearman: 0.009546\n",
      "Train Epoch: 3 [390/2296 (42%)]\tLoss: 0.283393 \t spearman: 0.011500\n",
      "Train Epoch: 3 [420/2296 (46%)]\tLoss: 0.280908 \t spearman: 0.017563\n",
      "Train Epoch: 3 [450/2296 (49%)]\tLoss: 0.277746 \t spearman: 0.006822\n",
      "Train Epoch: 3 [480/2296 (52%)]\tLoss: 0.275743 \t spearman: -0.000899\n",
      "Train Epoch: 3 [510/2296 (56%)]\tLoss: 0.271513 \t spearman: -0.000699\n",
      "Train Epoch: 3 [540/2296 (59%)]\tLoss: 0.269912 \t spearman: -0.006871\n",
      "Train Epoch: 3 [570/2296 (62%)]\tLoss: 0.270152 \t spearman: -0.010435\n",
      "Train Epoch: 3 [600/2296 (65%)]\tLoss: 0.268970 \t spearman: -0.010643\n",
      "Train Epoch: 3 [630/2296 (69%)]\tLoss: 0.269019 \t spearman: -0.015406\n",
      "Train Epoch: 3 [660/2296 (72%)]\tLoss: 0.269283 \t spearman: -0.006387\n",
      "Train Epoch: 3 [690/2296 (75%)]\tLoss: 0.268704 \t spearman: -0.005262\n",
      "Train Epoch: 3 [720/2296 (78%)]\tLoss: 0.266516 \t spearman: -0.005536\n",
      "Train Epoch: 3 [750/2296 (82%)]\tLoss: 0.265878 \t spearman: -0.007213\n",
      "Train Epoch: 3 [780/2296 (85%)]\tLoss: 0.266243 \t spearman: -0.012156\n",
      "Train Epoch: 3 [810/2296 (88%)]\tLoss: 0.266051 \t spearman: -0.017589\n",
      "Train Epoch: 3 [840/2296 (92%)]\tLoss: 0.264903 \t spearman: -0.014743\n",
      "Train Epoch: 3 [870/2296 (95%)]\tLoss: 0.265500 \t spearman: -0.015891\n",
      "Train Epoch: 3 [900/2296 (98%)]\tLoss: 0.265898 \t spearman: -0.019093\n",
      "Train Epoch: 3  loss=2.65e-01  rho=-0.02 \n",
      "Test Epoch: [0/2296 (0%)]\tLoss: 0.311707 \t spearman: -0.716498\n",
      "Test Epoch: [30/2296 (13%)]\tLoss: 0.260585 \t spearman: 0.081852\n",
      "Test Epoch: [60/2296 (26%)]\tLoss: 0.275354 \t spearman: -0.030197\n",
      "Test Epoch: [90/2296 (39%)]\tLoss: 0.278184 \t spearman: 0.030690\n",
      "Test Epoch: [120/2296 (52%)]\tLoss: 0.278886 \t spearman: 0.067340\n",
      "Test Epoch: [150/2296 (65%)]\tLoss: 0.276166 \t spearman: 0.019690\n",
      "Test Epoch: [180/2296 (78%)]\tLoss: 0.276800 \t spearman: 0.045853\n",
      "Test Epoch: [210/2296 (91%)]\tLoss: 0.278192 \t spearman: 0.041454\n",
      "Test Epoch:  loss=2.77e-01  rho=0.04 \n",
      "Train Epoch: 4 [0/2296 (0%)]\tLoss: 0.319511 \t spearman: -0.338062\n",
      "Train Epoch: 4 [30/2296 (3%)]\tLoss: 0.221366 \t spearman: 0.108912\n",
      "Train Epoch: 4 [60/2296 (7%)]\tLoss: 0.231824 \t spearman: 0.108703\n",
      "Train Epoch: 4 [90/2296 (10%)]\tLoss: 0.236360 \t spearman: 0.066229\n",
      "Train Epoch: 4 [120/2296 (13%)]\tLoss: 0.239067 \t spearman: 0.014834\n",
      "Train Epoch: 4 [150/2296 (16%)]\tLoss: 0.249380 \t spearman: 0.005930\n",
      "Train Epoch: 4 [180/2296 (20%)]\tLoss: 0.254778 \t spearman: 0.008748\n",
      "Train Epoch: 4 [210/2296 (23%)]\tLoss: 0.252359 \t spearman: 0.001706\n",
      "Train Epoch: 4 [240/2296 (26%)]\tLoss: 0.248110 \t spearman: 0.009216\n",
      "Train Epoch: 4 [270/2296 (29%)]\tLoss: 0.249283 \t spearman: 0.015084\n",
      "Train Epoch: 4 [300/2296 (33%)]\tLoss: 0.253505 \t spearman: 0.022752\n",
      "Train Epoch: 4 [330/2296 (36%)]\tLoss: 0.256374 \t spearman: 0.017056\n",
      "Train Epoch: 4 [360/2296 (39%)]\tLoss: 0.257494 \t spearman: 0.022374\n",
      "Train Epoch: 4 [390/2296 (42%)]\tLoss: 0.260775 \t spearman: 0.027520\n",
      "Train Epoch: 4 [420/2296 (46%)]\tLoss: 0.262563 \t spearman: 0.038977\n",
      "Train Epoch: 4 [450/2296 (49%)]\tLoss: 0.264987 \t spearman: 0.035671\n",
      "Train Epoch: 4 [480/2296 (52%)]\tLoss: 0.266524 \t spearman: 0.031292\n",
      "Train Epoch: 4 [510/2296 (56%)]\tLoss: 0.266928 \t spearman: 0.036808\n",
      "Train Epoch: 4 [540/2296 (59%)]\tLoss: 0.267086 \t spearman: 0.025948\n",
      "Train Epoch: 4 [570/2296 (62%)]\tLoss: 0.269376 \t spearman: 0.007920\n",
      "Train Epoch: 4 [600/2296 (65%)]\tLoss: 0.268278 \t spearman: -0.009170\n",
      "Train Epoch: 4 [630/2296 (69%)]\tLoss: 0.266414 \t spearman: -0.010681\n",
      "Train Epoch: 4 [660/2296 (72%)]\tLoss: 0.266402 \t spearman: -0.010724\n",
      "Train Epoch: 4 [690/2296 (75%)]\tLoss: 0.266149 \t spearman: -0.019973\n",
      "Train Epoch: 4 [720/2296 (78%)]\tLoss: 0.264443 \t spearman: -0.007926\n",
      "Train Epoch: 4 [750/2296 (82%)]\tLoss: 0.262614 \t spearman: 0.001213\n",
      "Train Epoch: 4 [780/2296 (85%)]\tLoss: 0.261579 \t spearman: 0.001139\n",
      "Train Epoch: 4 [810/2296 (88%)]\tLoss: 0.261659 \t spearman: -0.006161\n",
      "Train Epoch: 4 [840/2296 (92%)]\tLoss: 0.261013 \t spearman: -0.005540\n",
      "Train Epoch: 4 [870/2296 (95%)]\tLoss: 0.261154 \t spearman: 0.003505\n",
      "Train Epoch: 4 [900/2296 (98%)]\tLoss: 0.261902 \t spearman: -0.003786\n",
      "Train Epoch: 4  loss=2.62e-01  rho=0.00 \n",
      "Test Epoch: [0/2296 (0%)]\tLoss: 0.465823 \t spearman: 0.273230\n",
      "Test Epoch: [30/2296 (13%)]\tLoss: 0.267128 \t spearman: -0.041785\n",
      "Test Epoch: [60/2296 (26%)]\tLoss: 0.265467 \t spearman: 0.028409\n",
      "Test Epoch: [90/2296 (39%)]\tLoss: 0.262379 \t spearman: 0.026856\n",
      "Test Epoch: [120/2296 (52%)]\tLoss: 0.268205 \t spearman: 0.016154\n",
      "Test Epoch: [150/2296 (65%)]\tLoss: 0.265778 \t spearman: 0.011171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch: [180/2296 (78%)]\tLoss: 0.264730 \t spearman: nan\n",
      "Test Epoch: [210/2296 (91%)]\tLoss: 0.268064 \t spearman: nan\n",
      "Test Epoch:  loss=2.74e-01  rho=nan \n"
     ]
    }
   ],
   "source": [
    "\n",
    "k_folds = 5\n",
    "learning_rate = 5e-6\n",
    "num_epochs = 4\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "dataset = MutationDataset(tokenizer,train)\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_rho_history = []\n",
    "test_rho_history = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=test_subsampler)\n",
    "\n",
    "    model = ProtBertStab(pretrained=True)\n",
    "\n",
    "    num_freeze_layers = 22\n",
    "    \n",
    "    # FREEZE LAYERS\n",
    "    if num_freeze_layers>0:\n",
    "        for name, param in list(\n",
    "            model.named_parameters())[:5+16*num_freeze_layers]:     \n",
    "                param.requires_grad = False\n",
    "\n",
    "    torch.save(model.config, SAVE_PATH+'config.pth')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    # defining the loss function\n",
    "    criterion = RMSELoss()\n",
    " \n",
    "  \n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    best_rho = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss , rho_train = train_epoch( model, optimizer, criterion, train_dl, epoch)\n",
    "       \n",
    "\n",
    "        test_loss , rho_test = test_epoch(model, criterion, val_dl)\n",
    "        \n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_rho_history.append(rho_train)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_rho_history.append(rho_test)\n",
    "\n",
    "        if abs(rho_test) > best_rho : \n",
    "          best_rho = abs(rho_test)\n",
    "\n",
    "\n",
    "          torch.save(model, SAVE_PATH+ f'Prot_bert_VER-{VER}.pth')\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7169,
     "status": "ok",
     "timestamp": 1671680739773,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "vRcfUeThZeMr"
   },
   "outputs": [],
   "source": [
    "torch.save(model , SAVE_PATH+f'prot_{VER}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1671680739774,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "V20WQtD05z-M",
    "outputId": "39390f9c-c2ae-4b10-87bd-850891ebc7cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7bc9e476d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwUVbbA8d/JRvYQSFjCDqISdomIMIq4ggi4Iigq6gyjMzrO8+nTee6OzrjMGxWXcUURZgDFUUERUAfBUVCWAWRTdglrgIQQQgJJzvujKqETOiFAOtVJn+/n0x+rq6qrTqWxTt97694rqooxxhhTUZjXARhjjAlOliCMMcb4ZQnCGGOMX5YgjDHG+GUJwhhjjF+WIIwxxvhlCcIELRH5TERuCoI4HhWRiV7HYUxtswRhAkJEVEROOZljqOogVR1fUzEFgoicJyKZNXSsr0Tkl1Vsb+v+Xf9TYX2KiBwSkU0+634hIt+KyD4R2Ssi34jIme620SJSLCJ5FV5plZz3pL9LUzdZgjCeEJEIr2Oow2JFpIvP++uAjaVvRCQR+AR4EWgEtAAeAwp9PjNfVeMrvLbVQuymDrEEYWqciMxzF5e5v0yvLf2lLSL3icgO4G0RSRaRT0QkS0Sy3eWWPscp+0Xt/ur9t4j8xd13o4gMqiKG+0VkvYjsF5FVInKFz7YqjyUi7URkrvvZz4GUSs4RB3wGpPn+CheRMJ/z7xGR90SkkfuZaBGZ6K7PEZGFItJURJ4EzgFeco/zUhV/4gmAb9XbjcC7Pu9PBVDVSaparKoHVXW2qi6v4pjHTUSSRORd9/vbLCIPikiYu+0U92+4T0R2i8gUd72IyHMisktEckXkhwrJzgQRSxCmxqnque5id/eX6RT3fTOcX7RtgDE4//7edt+3Bg4CVd0YzwJ+xLlhPwO8JSJSyb7rcW64STi/nieKSPNqHusfwGJ32x8pfzP2vc4DwCBgW4Vf4XcClwP9gTQgG3jZ/dhNbkytgMbAbcBBVX0A+Bq4wz3OHVX8HSYCI0QkXETSgXjgO5/tPwHFIjJeRAaJSHIVxzoZL+JcS3uca70RuNnd9kdgNpAMtHT3BbgYOBcniSUBw4E9AYrPnCRLEKY2lQCPqGqh+6t2j6p+oKr5qrofeBLnRlOZzar6hqoWA+OB5kBTfzuq6vuquk1VS9wEtRbofaxjiUhr4EzgITfOecD047zO24AHVDVTVQuBR4Gr3Wq1wziJ4RT31/1iVc09zuNn4iS3C3FuyhMqXHsu8AtAgTeALBGZJiK+f6s+bgmm9LX+eAIQkXBgBPAHVd2vqpuA/wNucHc5jJP401S1QFX/7bM+ATgdEFVdrarbj+fcpvZYgjC1KUtVC0rfiEisiLzmVk/kAvOAhu7Nx58dpQuqmu8uxvvbUURuFJGlpTdAoAvlq4oqO1YakO2WDkptrub1lWoDfOhz7tVAMU4ymwDMAiaLyDYReUZEIo/z+OBUKY0GRlIhQQC4N97RqtoS59rTgOd9dlmgqg19Xh2O8/wpQCTl/zabcdo7AP4HEOB7EVkpIre4cf0Lp5T4MrBLRF5320xMELIEYWpTxaGD/xs4DThLVRNxqh7AubGcMBFpg/PL+Q6gsao2BFZU87jbgWS3faFU6yr29zcc8hZgUIUbcLSqblXVw6r6mKqmA32By3BKAZUdqzIfAIOBDar6c1U7quoa4B2cRFFTdnOklFCqNbDVPecOVf2VqqYBvwZeKX0SSlXHqmovIB2nquneGozL1CBLECZQduLUTVclAafdIcdtxH2khs4dh3OzzQIQkZup5s1RVTcDi4DHRCRKRH4BDKniIzuBxiKS5LPuVeBJN1EhIqkiMsxdHiAiXd1SUi7OTbbE51jH+puVxnkAOB846rFYETldRP67tMFfRFrhlDQWVOfYlYhyG9ijRSTaXfceznUmuNd6N077CCJyjRx54CAb5/soEZEzReQst9R0ACjgyPWbIGMJwgTKo8B4t5pleCX7PA/E4PwaXQDMrIkTq+oqnPrw+Tg33a7AN8dxiOtwGrH34iStdyvb0f11PgnY4F5rGvACMA2YLSL7ca7tLPcjzYCpOMlhNTCXI1VEL+C0VWSLyNhqXOciVfXXdrDfPd93InLAPf8KnBJbqbPl6H4QZ1ZxupU4ybz0dTNOY/wBYAPwb5zG/XHu/me6589z/xZ3qeoGIBGndJeNUyW1B3j2WNdqvCE2YZAxxhh/rARhjDHGL0sQxhhj/LIEYYwxxi9LEMYYY/yqNwOmpaSkaNu2bb0Owxhj6pTFixfvVtVUf9vqTYJo27YtixYt8joMY4ypU0Sk0pECrIrJGGOMX5YgjDHG+GUJwhhjjF/1pg3CGFN/HT58mMzMTAoKCo69s/ErOjqali1bEhlZ/cGDLUEYY4JeZmYmCQkJtG3blsrniDKVUVX27NlDZmYm7dq1q/bnrIrJGBP0CgoKaNy4sSWHEyQiNG7c+LhLYJYgjDF1giWHk3Mifz9LEKow+0HYOA9KbFh6Y4wpZQkiexMsegfGD4Hnu8Dnj8DOVV5HZYwJIjk5Obzyyisn9NlLL72UnJycau//6KOP8pe//OWEzlXTLEE0agf3/ARXj4OmXeDbF+FvZ8Orv3CWc20+dWNCXVUJoqioqMrPzpgxg4YNGwYirICzBAEQFQtdroLr34P//hEGPQPhUU7V03Pp8O7lsHQSFOZ5HakxxgP3338/69evp0ePHtx777189dVXnHPOOQwdOpT09HQALr/8cnr16kXnzp15/fXXyz7btm1bdu/ezaZNm+jUqRO/+tWv6Ny5MxdffDEHDx6s8rxLly6lT58+dOvWjSuuuILs7GwAxo4dS3p6Ot26dWPEiBEAzJ07lx49etCjRw969uzJ/v37T/q6682MchkZGVrjYzHtXgvL34PlUyBnM0TGwumDodu10H4AhNtTwsbUhtWrV9OpUycAHpu+klXbcmv0+OlpiTwypHOl2zdt2sRll13GihUrAPjqq68YPHgwK1asKHtsdO/evTRq1IiDBw9y5plnMnfuXBo3blw2TlxeXh6nnHIKixYtokePHgwfPpyhQ4cyatSocud69NFHiY+P55577qFbt268+OKL9O/fn4cffpjc3Fyef/550tLS2LhxIw0aNCAnJ4eGDRsyZMgQ7r//fvr160deXh7R0dFERJS/R/n+HUuJyGJVzfB33VaCqEpKRzj/AbhrGdwyC7qPgLWfw9+vhr+eDp/dD9v+4zR0G2NCSu/evcv1KRg7dizdu3enT58+bNmyhbVr1x71mXbt2tGjRw8AevXqxaZNmyo9/r59+8jJyaF///4A3HTTTcybNw+Abt26cf311zNx4sSyJNCvXz/uvvtuxo4dS05OzlHJ4UTYT+DqEIHWfZzXwKecJLF8Mix6C777G6Sc6pQqul4DyW28jtaYeq2qX/q1KS4urmz5q6++4osvvmD+/PnExsZy3nnn+e1z0KBBg7Ll8PDwY1YxVebTTz9l3rx5TJ8+nSeffJIffviB+++/n8GDBzNjxgz69evHrFmzOP3000/o+KUsQRyviAbQ6TLndTAbVn7kVEP964/Oq3Vf6H4tpA+DmGSvozXG1ICEhIQq6/T37dtHcnIysbGxrFmzhgULFpz0OZOSkkhOTubrr7/mnHPOYcKECfTv35+SkhK2bNnCgAED+MUvfsHkyZPJy8tjz549dO3ala5du7Jw4ULWrFljCcJTMcmQcbPzyt4MP7wHy6bA9Ltgxr1w6kCnZNHxYoiI8jpaY8wJaty4Mf369aNLly4MGjSIwYMHl9s+cOBAXn31VTp16sRpp51Gnz59auS848eP57bbbiM/P5/27dvz9ttvU1xczKhRo9i3bx+qyu9+9zsaNmzIQw89xJw5cwgLC6Nz584MGjTopM9vjdQ1TdVpl1j+HqyYCgeynETS+QroNgJa9XaqrIwx1eavcdUcv+NtpLYSRE0TgRZnOK+Ln4ANc5ynoJZOgkXjILktdB3ulCxSTvE6WmOMqZQliEAKj4COFzmvwv2w+hOncXveszDvGWjRyylVdLkS4lK8jtYYY8qxBFFbGiRAj5HOK3cb/DDVqYb67F6Y9Qc45ULoNhxOuxQiY7yO1hhjLEF4IjEN+v3Oee1c6VRBLX8ffpoJUQnOE1DdhkPbcyDMuqoYY7xhCcJrTTvDRY/DBY/A5m+cp6BWfQxLJ0JiC+h6tdNe0TQ4nv02xoQOSxDBIiwc2p3rvAb/BX6c4VRBzX8ZvnkBmnZ1ShVdr4HE5l5Ha4wJAVZ/EYwiY5zBA6+b4g4e+KzTQe/zh+CvneDdYbD0H07DtzEm4E5muG+A559/nvz8fL/bzjvvPILiEX0/LEEEu7gUOGsM/OpLuGMx9P8fZw6Lj26HZzvC1FudoT+Kqx5y2Bhz4gKZIIKZJYi6JOUUGPC/8LulcMts54modV+UHzxw6xIbPNCYGlZxuG+AZ599ljPPPJNu3brxyCOPAHDgwAEGDx5M9+7d6dKlC1OmTGHs2LFs27aNAQMGMGDAgCrPM2nSJLp27UqXLl247777ACguLmb06NF06dKFrl278txzzwH+h/yuadYGUReJQOuznNfAp2HtbOdJqHKDBw53OuTZ4IGmvvnsftjxQ80es1lXGPRUpZufeuopVqxYwdKlSwGYPXs2a9eu5fvvv0dVGTp0KPPmzSMrK4u0tDQ+/fRTwBmjKSkpib/+9a/MmTOHlJTK+ztt27aN++67j8WLF5OcnMzFF1/MRx99RKtWrdi6dWvZUOOls9M99dRT5Yb8DgQrQdR1EVHOwIHXTnBmxhvyAsSlwr+egBe6wbhBsOhtZ2BBY0yNmD17NrNnz6Znz56cccYZrFmzhrVr19K1a1c+//xz7rvvPr7++muSkpKqfcyFCxdy3nnnkZqaSkREBNdffz3z5s2jffv2bNiwgTvvvJOZM2eSmJgI+B/yu6ZZCaI+iUmGXqOdV/Zm+OF9p2Txye/hs/+BUy/xGTywwbGOZkxwquKXfm1RVf7whz/w61//+qhtS5YsYcaMGTz44INccMEFPPzwwyd1ruTkZJYtW8asWbN49dVXee+99xg3bpzfIb9rOlFYCaK+Sm4D594Dv/0exnwFZ/4Sfl4AU0bBX06F6b933lt7hTHHVHG470suuYRx48aRl+dMQ7x161Z27drFtm3biI2NZdSoUdx7770sWbLE7+f96d27N3PnzmX37t0UFxczadIk+vfvz+7duykpKeGqq67iiSeeYMmSJeWG/H766afZt29fWSw1KaAlCBEZCLwAhANvqupTFbbfBvwWKAbygDGqusrd9gfgVnfb71R1ViBjrbdEIK2n87roj7DhK2c8qGWTYfHb0LCNU6qwwQONqVTF4b6fffZZVq9ezdlnnw1AfHw8EydOZN26ddx7772EhYURGRnJ3/72NwDGjBnDwIEDSUtLY86cOX7P0bx5c5566ikGDBiAqjJ48GCGDRvGsmXLuPnmmykpKQHgz3/+c6VDfte0gA33LSLhwE/ARUAmsBAYWZoA3H0SVTXXXR4K/EZVB4pIOjAJ6A2kAV8Ap6pqcWXnC5rhvuuKssEDp8DGuaAl7uCB10LnKyE+1esIjSljw33XjGCak7o3sE5VN6jqIWAyMMx3h9Lk4IoDSrPVMGCyqhaq6kZgnXs8U1NKBw+88SP4r1XO0OTFh5y2iv87Df4+3BlQ8FDde3bbGFMzAlnF1ALY4vM+Ezir4k4i8lvgbiAKON/ns75z9mW660wgJDaHvnc6r52rnFLFD+/DB7PcwQOH+gweGO51tMaYWuJ5I7WqvqyqHYD7gAeP57MiMkZEFonIoqysrMAEGGqapsNFj8HvV8BN06HzMFg93Rne47kuMPshZwRaY2pZfZn90isn8vcLZILYCrTyed/SXVeZycDlx/NZVX1dVTNUNSM11erMa1RYmDNw4LCXnf4VV78NzbvDglfgb33hb/2cQQRzt3kdqQkB0dHR7Nmzx5LECVJV9uzZQ3R09HF9LpCN1BE4jdQX4NzcFwLXqepKn306qupad3kI8IiqZohIZ+AfHGmk/hLoaI3UQeDAblj5ofMU1NZFgDiJpPsI6DTEadswpoYdPnyYzMxMCgoKvA6lzoqOjqZly5ZERkaWW19VI3XAEoR74kuB53Eecx2nqk+KyOPAIlWdJiIvABcCh4Fs4I7SBCIiDwC3AEXA71X1s6rOZQnCA3vWu5MdTXEGEIyIgdMHO09CdRgA4ZHHPIQxxlueJYjaZAnCQ6qQudApVaz8pzOsR2yKO9nRcEg7w+mPYYwJOpYgTO0pOgTrPndKFT/OhOJCaNzR7Yx3DSS39TpCY4wPSxDGGwdznOlTl09xplMFaH22U6rofIUzdpQxxlOWIIz3cn52+lYsmwK7f4TwKGfQwO4jbPBAYzxkCcIED1XYvsztjDcVDuyC6IZOiaLbtdC6j7VXGFOLLEGY4FRc5A4eOAXWfAKH86Fha5/BAzt6HaEx9Z4lCBP8CvOcJLF8ipM0tAQ6nA9Xj7O2CmMCyKvB+oypvgbxTnvEDR/C3avhgkdg49fw9qXWW9sYj1iCMMEnoRmcczeMmuo0br91Cexe53VUxoQcSxAmeLU/D0a7bRPjLoatS7yOyJiQYgnCBLe0nnDLLIiMg/FDYL3/2biMMTXPEoQJfimnwK2znSec/n4NrPin1xEZExIsQZi6IbE53DwDWmbA1Fvg+ze8jsiYes8ShKk7YpKdp5xOHQgz7oE5f3I63hljAsIShKlbImPg2onQ43qY+zR8ejeUVDpNiDHmJARyTmpjAiM8wpnpLi7FmdUufw9c+YaN52RMDbMEYeomEbjocYhLhdkPOnNQXPt3iE70OjJj6g2rYjJ1W9874fJXYdM3MP4yyMvyOiJj6g1LEKbu6zESRk6CrJ+cDnXZm7yOyJh6wRKEqR9OvQRu/Bjy98JbF8OOFV5HZEydZwnC1B+tz4JbZoKEO4P8bf7W64iMqdMsQZj6pUknuHUWxDeBCVfAmhleR2RMnWUJwtQ/DVs74zc1SYcp18OSCV5HZEydZAnC1E9xjeGm6dCuP0y7A/79nPW6NuY4WYIw9VeDeLjuPehyFXzxqNNfoqTE66iMqTOso5yp3yKi4Mo3IbYxzH8JDmQ5vbDDI72OzJigZwnC1H9hYTDoGYhrAnOecB6FHT4eouK8jsyYoGZVTCY0iED/e+Gy52H9l/DuMCdRGGMqZQnChJaMm+Ga8bB9Gbw9CPZt9ToiY4KWJQgTetKHwqgPnOTw1sXOEB3GmKNYgjChqd25cPOnUFwI4y6BzEVeR2RM0LEEYUJX8+5Oh7roRBg/BNZ94XVExgQVSxAmtDXu4CSJRh3gH9fCD1O9jsiYoGEJwpiEZk51U6uz4INbYcGrXkdkTFCwBGEMQHQSjPonnH4ZzLwPvvyjDc1hQp4lCGNKRUY7j8D2vAG+/gtMvwuKi7yOyhjPWE9qY3yFR8DQF53hwr/+P8jfA1e95SQPY0KMlSCMqUgELngYBj4Faz6BiVdBwT6vozKm1gU0QYjIQBH5UUTWicj9frbfLSKrRGS5iHwpIm18tj0tIivc17WBjNMYv/rcDle+AVsWwNuDYf9OryMyplYFLEGISDjwMjAISAdGikh6hd3+A2SoajdgKvCM+9nBwBlAD+As4B4RSQxUrMZUqttwGDkF9q6HcRfD3g1eR2RMrQlkCaI3sE5VN6jqIWAyMMx3B1Wdo6r57tsFQEt3OR2Yp6pFqnoAWA4MDGCsxlSu44XO5EMF++CtS2D7cq8jMqZWBDJBtAC2+LzPdNdV5lbgM3d5GTBQRGJFJAUYALSq+AERGSMii0RkUVZWVg2FbYwfLTOcDnXhkfDOYNj4tdcRGRNwQdFILSKjgAzgWQBVnQ3MAL4FJgHzgeKKn1PV11U1Q1UzUlNTazFiE5JST4NbZ0NCc6fhetU0ryMyJqACmSC2Uv5Xf0t3XTkiciHwADBUVQtL16vqk6raQ1UvAgSwITeN95Jawi0zoVlXeP8mWPyO1xEZEzCBTBALgY4i0k5EooARQLmfXCLSE3gNJzns8lkfLiKN3eVuQDdgdgBjNab6YhvBTdOgw/lOZ7p5z1qva1MvBayjnKoWicgdwCwgHBinqitF5HFgkapOw6lSigfeFxGAn1V1KBAJfO2uywVGqap1aTXBIyoORk6Gj34D/3oCDuyGS/7sTG9qTD0R0J7UqjoDpy3Bd93DPssXVvK5ApwnmYwJXuGRcMVrEJcCC15xksTlf4OIKK8jM6ZG2FAbxpyMsDC45E8QlwpfPgYH98LwCdAg3uvIjDlpVh425mSJwDl3w5CxsOEreHcoHNjjdVTGnDRLEMbUlF43OaWHHSucaUxzthz7M8YEMUsQxtSkTpfBDR9C3k5462LYtcbriIw5YZYgjKlpbfvBzTNAi52SxJbvvY7ImBNiCcKYQGjW1RmaIyYZxg+FtZ97HZExx80ShDGB0qidMzRHSkeYNAKWTfE6ImOOiyUIYwIpvgmM/hRanw0fjoH5L3sdkTHVZgnCmECLToTrp0KnITDrf+HzR2xoDlMnWIIwpjZERsM146HXzfDN8zDtDii20WNMcLOe1MbUlrBwuOw5p9f1vGcgfy9cPQ4iY7yOzBi/rARhTG0SgfMfgEHPwo+fwYQr4WCO11EZ45clCGO8cNYYuOpNyFwIb18K+3d4HZExR7EEYYxXul4N178H2ZvgrYtgz3qvIzKmnCoThDsVaOlyvwrb7ghUUMaEjA7nw+jpUJjnDM2xbanXERlT5lgliLt9ll+ssO2WGo7FmNDUopfToS4yBt65DDbM9ToiY4BjJwipZNnfe2PMiUrp6CSJpJbw96th5UdeR2TMMROEVrLs770x5mQkpjmD/KX1hPdHw8K3vI7IhLhj9YM4XUSW45QWOrjLuO/bBzQyY0JRbCO44SMnQXx6NxzIgv73OY/HGlPLjpUgOtVKFMaYI6JiYcTfYdqd8NWfnSQx6Bmno50xtajKBKGqm33fi0hj4FzgZ1VdHMjAjAlp4ZEw7BWIS4FvX4T8PXDFaxDRwOvITAg51mOun4hIF3e5ObAC5+mlCSLy+1qIz4Sog4eKKSwq9joMb4WFwcVPwEWPw8oP4R/DoXC/11GZEHKsKqZ2qrrCXb4Z+FxVbxSRBOAb4PmARmdCQvaBQ6zclsvKbfvK/rtx9wGSY6N49YZenNm2kdcheqvfXRCb4lQ5jR/ijAwbl+J1VCYEHCtBHPZZvgB4A0BV94tIScCiMvWSqrJtXwErt5YmglxWbdvHtn0FZfukJUWTnpbE4G5pTF+2jevf+I6nrurKlWe09DDyINDzeqcB+/3RzjSmo/4JyW28jsrUc8dKEFtE5E4gEzgDmAkgIjFAZIBjM3VYcYmyISuvXMlg1fZccvKd3xxhAu1T48lo24jOaYl0TksiPS2RRnFRZce4pV9bbp+4hLvfW8b6rDz++6LTCAsL4ad5ThvkPOE06Vo3SXwATTt7HZWpx0SrmLhERJoAjwPNgZdVdba7fgDQS1X/UitRVkNGRoYuWrTI6zBCUsHhYn7csb9cMlizI5eCw04hMyoijNObJdA5LZH0tCQ6pyVyerMEYqOOPdr84eISHv54BZO+38KgLs346/AexESF+NM8O1c6o8AWHYTr3oPWfbyOyNRhIrJYVTP8bqsqQdQlliBqx778w6zcvo9VZVVEuazLyqO4xPl3lBAdQXpzp0TQOS2Rzi0S6ZAaT2T4iY8Lqaq89e+NPDljNV3SknjzpgyaJkbX1CXVTdmbYcIVkLvVmYjotIFeR2TqqBNOECIyraoDq+rQk4ytxliCqFmqys7cwnINxyu35ZKZfbBsn6aJDY4kAreaqGVyDBKgTl1frNrJXZP/Q0J0JG/elEGXFkkBOU+dkZflDMux4wcY+qLTTmHMcTqZBJEFbAEmAd9RYfwlVQ2aUcUsQZy4khJl454DZYlglVsy2HPgUNk+7VLiSPdJBJ3TEkmJr/1n8ldvz+WX4xex98Ahnru2BwO7NKv1GIJK4X6YfD1snOs8DtvvLq8jMnXMySSIcOAiYCTQDfgUmKSqKwMR6MmwBFE9hUXFrN2Z51MyyGX19lzyDzl9DiLDhVObJpRLBKc3TyS+QfDMTrtrfwFj3l3M0i053DfwdG7r3z5gpZY6oagQPvy101ei751w4eNOHwpjqqGqBHGsntTFOE8uzRSRBjiJ4isReUxVX6r5UE1N2l9wuKytoPQporU791PkthfERYWTnpbI8IxWZaWDjk0SiIoI7ptLk4RoJo/pw71Tl/P0zDWs25XHn67sQoOIEG28jmgAV70FsY2dXtcH9sDQsU5vbGNOwjF/FrqJYTBOcmgLjAU+DGxY5njt2l9Q1mhcWjrYvCe/bHtKfAM6pyUy4LTUspJB60axdfax0ejIcMaO6EGH1Die/2ItW/bm8+oNvco9JhtSwsLh0r9AXKozflP+HrjmHWdcJ2NO0LGqmN4FugAzgMk+vaqDTqhUMZWUKD/vzT/SXrDdKR1k7S8s26d1o9hyDced0xJpUo+f+pm2bBv3vL+MZonRjBudwSlNErwOyVsL34RP74FWveG6KRCT7HVEJoidTBtECXDAfeu7owCqqok1FuVJqo8J4nBxSbn2glVuNVFeYREAEWHCKU3iyz1J1CktkcTo0KtaWPJzNmPeXUxhUTEvX3cG556a6nVI3lr5IfxzDDTqADf805lrwhg/rB9EHXCgsIjV24/0LVi5fR8/7cjjULHT2SwmMpxOzRN8kkESHZvGEx0ZovXufmzNOcit7yxk7a48Hh2Szg1nt/U6JG9t+Mp5wikmGW740Jm1zpgKLEEEmT15hWUNx6WPlW7cc4DSr6JRXJTb69gdgqJ5Iu1S4givo+0FtSmvsIi7Jv2HL9fsYnTftjw4uBMRJ9FJr87b9h+YeDWgcP37zvzXxviwBOERVSUz+2BZEihNCjtyjwxO16JhTLm2gs4tEmmWGB3aj22epOIS5anPVvPG1xs599RUXrquZ0hWu5XZsx4mXO483TRiInQ43+uITBDxLNFHfzsAABUISURBVEGIyEDgBSAceFNVn6qw/W7gl0ARkAXcUjpJkYg8g/P0VBjwOXCXVhGs1wmiqLiE9VkHyvU8XrUtl9wCp70gTCjXXpCelkh680QaxoboUze1YNL3P/PQRytolxLHuNFn0qpRCD/Rk7sdJl4Fu3+CK1+DLld5HZEJEp4kCLeT3U84He0ygYXASFVd5bPPAOA7Vc0XkduB81T1WhHpCzyLM3sdwL+BP6jqV5WdrzYTxMFDxazekeszHtE+1uzYT2GR017QICKM05snlnuS6PRmCdZe4IFv1+/m9olLCA8TXgv1uSUO5sCkEfDzAmcK07PGeB2RCQIn3FHuJPUG1qnqBjeIycAwoCxBqOocn/0XAKNKNwHRQBTOE1ORwM4AxlqpnPyKk9nksiErD7evGUkxkXROS+TGs9uUDVndPiUutOu9g0jfDil8+Ju+3Dp+kc0tEdPQaax+/2b47F7I3w3n/QGsOtNUIpAJogXOOE6lMoGzqtj/VuAzAFWdLyJzgO04CeIlVV1d8QMiMgYYA9C6deuTCtZ3MptVPk8Tbc05Mjhd86RoOqclcmnX5mWlgxYNAzc4nakZ7VPj+fA3fW1uCYDIGLh2Iky/C+Y+DXm7YPD/OR3tjKkgKAbYEZFRQAbQ331/CtAJKP2p97mInKOqX/t+TlVfB14Hp4rpRM69K7eA/3pvKau25ZLtTmYjAu1T4ujVJpkbz25T9jRRyPbSrQcaxkbx7q29efjjFbw8Zz0bsg6E7twS4REw7CVn2tJvnnd6XV/1pjNkhzE+ApkgtgKtfN63dNeVIyIXAg8A/VW1tDvwFcACVc1z9/kMOBv4uuLnT1ZSbCR5hcVc0rlZ2YQ2nZpXbzIbU7dEhofxpyu60iE1nidnrCbztfmhO7eECFz0mDM0x+wHnAbsEf+A6KDp+2qCQCAbqSNwGqkvwEkMC4HrfEeCFZGewFRgoKqu9Vl/LfArYCBOFdNM4HlVnV7Z+bx+isnULTa3hI9lk+Gj3zjTl476AOKbeB2RqUVVNVIHrCVVVYuAO4BZwGrgPVVdKSKPi0jpREPPAvHA+yKy1GeCoqnAeuAHYBmwrKrkYMzxujC9KVNv70t4mHDNq/OZuWKH1yF5p/sIGDkZdq+Fty6GvRu9jsgECesoZ0KazS3hY8v38PdrnLaIUR9As65eR2RqgSclCGPqgtK5JYZ0T+PpmWu45/3lFBYVex2WN1r1hltmgoTD25fCpm+8jsh4zBKECXmlc0v8/sKOfLAkkxve/J69PtOthpQmneDW2RDfFCZcAWs+9Toi4yFLEMYAIsLvLzyVsSN7sjQzh8tf/oZ1u/Z7HZY3GraCW2Y5jdZTRsGSCV5HZDxiCcIYH0O7pzF5TB/yDxVzxSvfMu+nLK9D8kZcY7hpOrQ/D6bdAV//FepJe6WpPksQxlRwRutkPr6jHy0axnDzOwuZMH+T1yF5o0E8jJziDOz35WMw63+hpMTrqEwtsgRhjB8tGsYw9fa+nHdqKg99vJJHp62kqDgEb44RUXDlm9D717DgFfhwDGxfBgX7vI7M1ALrLmxMJeIbRPD6jRllc0ts2H0gNOeWCAuDQU9DfCr86wn44X1nfUwyJLeD5LbOq5HPcmILG9+pHrB+EMZUg80t4cr6CbJWQ/Ymp0Nd9ibntW8LlBQd2S8sEhq2PjpxJLeD5DbQIMGL6I0fNqOcMTXA5paoQnER5GYenTiyN8LeTVBYoUoqNsVP4nCXE5o7pRZTKyxBGFNDNmTlcev4RWzNPhjac0scr4PZRyeOstJHJqhP+054A6eUUTFxNGoHDdtAVIiW3gLEEoQxNSgn/xC3T1zC/A17+O2ADqE7t0RNKTrkVFFVTBx73feH8srvH9+08raP+KY2AdJxsgRhTA07XFzCwx+vYNL3WxjUpVnozi0RaKqQv9cncbhVVqVJJHcrzgSUrogY/4kjuZ3TJhIZgkO7H4NXU44aU2/Z3BK1RMTptBfXGFr6uYcdLjhS+qhYhbVxLhzOL79/QlrlbR9xKVb6qMBKEMacJJtbIkipwoGsyts+9m8vv39UvE/iaHskgTRqB0mtnD4h9ZBVMRkTYKu35/LL8YvYe+AQz13bg4FdmnkdkjmWQ/mQ87Ofto+NkLMZigqO7CthTt8O3+RRVhJp5/QJqaOlD0sQxtQCm1uiHikpgbydRyeO0uUDu8rv3yDpyJNXFauwklpCePB2rrQEYUwtKThczL1TlzN92TauOqMlf7qyCw0irPG63inMc0oZ/to+cn6GYp/h4iXcSRKVtX3ENPTgAnzCs0ZqY2pH6dwSHVLjeP6LtWzZm8+rN/SiUVz9rL8OWQ3ineHQm3Y+eltJsdO+4a/tY/V0yN9Tfv+Y5KMTR2ky8XjIEitBGBMg05Zt4573l9EsMZpxozM4pYkNL2FwBjrM3uy/7aOqIUuOqr5qWyNDllgVkzEeWfJzNmPeXUxhUTEvX3cG556a6nVIJpgVFzl9Oypr+yjIKb9/bIqTKFr3gUuePKFTWhWTMR4pnVvi1ncWcvM7C3l0SDo3nN3W67BMsAqPcBu72/jffjDbf+KoWG1VQyxBGBNgpXNL3DXpPzz08UrWZx3gwcGdiAi3AenMcYpJdl5pPWvldPYv1JhaUDq3xK/Oacc7327ilvGLyC047HVYxlTJEoQxtSQ8THhgcDp/vrIr367bzVWvfMuWvfnH/qAxHrEEYUwtG9m7Ne/e2ptd+wsZ9vI3LNy01+uQjPHLEoQxHujbIYUPf9OXpJhIrn/jO/65JNPrkIw5iiUIYzzSPjWeD3/Tl15tkrn7vWU8O2sNJSX147FzUz9YgjDGQw1jo3j31t6M7N2Kl+es57f/WMLBQ8Veh2UMYAnCGM+Vzi3x4OBOzFy5g+GvzWdnbsGxP2hMgFmCMCYIiAi/PKc9b9yQwYasPIa99A0rtu7zOiwT4ixBGBNELkxvytTb+xIeJlzz6nxmrtjhdUgmhFmCMCbIdGqeyIe/7ctpzRK4beJi/vbVeurLmGmmbrEEYUwQapIQzeQxfRjSPY2nZ67hnveXU1hkjdemdtlYTMYEKZtbwnjNShDGBDER4fcXnsrYkT1ZmpnD5S9/w7pd+70Oy4QISxDG1AFDu6cxeUwf8g8Vc8Ur3zLvpyyvQzIhIKAJQkQGisiPIrJORO73s/1uEVklIstF5EsRaeOuHyAiS31eBSJyeSBjNSbYlc4t0aJhDDe/s5AJ8zd5HZKp5wKWIEQkHHgZGASkAyNFJL3Cbv8BMlS1GzAVeAZAVeeoag9V7QGcD+QDswMVqzF1RencEuedmspDH6/k0WkrKSou8TosU08FsgTRG1inqhtU9RAwGRjmu4ObCErHO14AtPRznKuBz3z2Myak2dwSprYEMkG0ALb4vM9011XmVuAzP+tHAJP8fUBExojIIhFZlJVldbImdNjcEqY2BEUjtYiMAjKAZyusbw50BWb5+5yqvq6qGaqakZpqk8Gb0GNzS5hACmSC2Aq08nnf0l1XjohcCDwADFXVwgqbhwMfqqqVn42phM0tYQIlkAliIdBRRNqJSBROVdE03x1EpCfwGk5y2OXnGCOppHrJGHOEzS1hAiFgCUJVi4A7cKqHVgPvqepKEXlcRIa6uz0LxAPvu4+zliUQEWmLUwKZG6gYjalPbG4JU9OkvgwClpGRoYsWLfI6DGM8p6q89e+NPDljNV3SknjzpgyaJkZ7HZYJUiKyWFUz/G0LikZqY0zN8Z1bYr3NLWFOgiUIY+qpC9ObMvW2voQJNreEOSGWIIypx9LTEvnojn6canNLmBNgCcKYeq5JQjRTxvThsm7NbW4Jc1xsPghjQkB0ZDgvjuxJh9R4XvjS5pYw1WMlCGNChIjwXxedygsjetjcEqZaLEEYE2KG9Wjhzi1RZHNLmCpZgjAmBJ3ROpmPfmtzS5iqWYIwJkS1TI5l6u196W9zS5hKWIIwJoTFN4jgjRsz+OUvbG4JczRLEMaEuPAw4cHLbG4JczRLEMYYwJ1b4pbe7MwtsLklDGAJwhjjo+8pKXz02342t4QBLEEYYyqwuSVMKUsQxpijNIyNYvwtvRlxps0tEcosQRhj/IqKCOPPV3blwcGdmLlyB8Nfm8/O3AKvwzK1yMZiMsZUqnRuibaN4/jd5P8w5MV/c1F6U1o1iqVlcgwtk2NplRxDo7goRMTrcE0NswRhjDmmC9Ob8sHtfXn44xV8+sN2cvLL95WIjQovlzBaJsfSqlHp+1gSYyIsgdRBliCMMdXSqXki79/WF4D9BYfJzD5IZvZBtuzNd5fz2ZJ9kIUb97K/sKjcZxMaRNCyrNQRQ6tkZ7m0JJIQHenFJZljsARhjDluCdGRdGoeSafmiX6378s/zJbsfDKz88slkc17DvDNut3kV2jwbhgb6TdxtHTfx0bZrcoL9lc3xtS4pNhIkmKT6NIi6ahtqsreA4eOlEDcRLJl70F+2rmff63ZRWFR+TGhGsdFlZVAKiaRFg1jiI4Mr61LCymWIIwxtUpEaBzfgMbxDejequFR20tKlN0HCtmy92BZCaT0vyu37mP2yh0cLi7fL6NJQoNyScNJIk47SPOkGKIi7IHNE2EJwhgTVMLChCYJ0TRJiKZXm+SjtheXKLv2F5Sruir97+LN2XyyfDvFPh37wgSaJUY71VWNyjekt0yOoXlSNBHhlkD8sQRhjKlTwsOE5klOyeDMto2O2l5UXML2fQXlGs4zs/PJ3HuQBev3sD13K6oVjxd9VNVV6X+bJkQTFhaaT2BZgjDG1CsR4WG0ahRLq0axQOOjth8qKmH7voNlVVhbyqqxDjL3pyx27S8st39kuNCiYflHd1v6PMqbGt+g3j7CawnCGBNSoiLCaNM4jjaN4/xuLzhczNac8o/wliaR2St3sufAoXL7N4gIK5cwShNIaYmkLncitARhjDE+oiPD6ZAaT4fUeL/b8w8VsdUnafgmkWWZOZV2IvT3CG+r5FiSYoO3D4glCGOMOQ6xURF0bJpAx6YJfreXdiKsWPrIzD7I9/46EUZHHFXq8G0HiW/g3W3aEoQxxtSgqjoRqiq5B4vK9f0obUjfvOcA/167m4OHj+5EeHTpw0kmLQLcidAShDHG1BIRqXYnwopVWD/u3M+Xa3ZxqEInwpT4KPq0b8xL151R4/FagjDGmCBRrU6EeYVHHt11/9soLiog8ViCMMaYOiIsTGiSGE2TRP+dCGv8fAE/gzHGmDrJEoQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL8sQRhjjPHLEoQxxhi/RFWPvVcdICJZwOaTOEQKsLuGwvFSfbkOsGsJVvXlWurLdcDJXUsbVU31t6HeJIiTJSKLVDXD6zhOVn25DrBrCVb15Vrqy3VA4K7FqpiMMcb4ZQnCGGOMX5Ygjnjd6wBqSH25DrBrCVb15Vrqy3VAgK7F2iCMMcb4ZSUIY4wxflmCMMYY41dIJQgRGSgiP4rIOhG538/2BiIyxd3+nYi0rf0oq6ca1zJaRLJEZKn7+qUXcR6LiIwTkV0isqKS7SIiY93rXC4iNT+vYg2pxrWcJyL7fL6Th2s7xuoQkVYiMkdEVonIShG5y88+deJ7qea11JXvJVpEvheRZe61POZnn5q9h6lqSLyAcGA90B6IApYB6RX2+Q3wqrs8ApjiddwncS2jgZe8jrUa13IucAawopLtlwKfAQL0Ab7zOuaTuJbzgE+8jrMa19EcOMNdTgB+8vPvq058L9W8lrryvQgQ7y5HAt8BfSrsU6P3sFAqQfQG1qnqBlU9BEwGhlXYZxgw3l2eClwgIlKLMVZXda6lTlDVecDeKnYZBryrjgVAQxFpXjvRHZ9qXEudoKrbVXWJu7wfWA20qLBbnfheqnktdYL7t85z30a6r4pPGdXoPSyUEkQLYIvP+0yO/odSto+qFgH7gMa1Et3xqc61AFzlFv+nikir2gmtxlX3WuuKs90qgs9EpLPXwRyLW0XRE+fXqq86971UcS1QR74XEQkXkaXALuBzVa30e6mJe1goJYhQMx1oq6rdgM858qvCeGcJzrg33YEXgY88jqdKIhIPfAD8XlVzvY7nZBzjWurM96KqxaraA2gJ9BaRLoE8XygliK2A76/olu46v/uISASQBOypleiOzzGvRVX3qGqh+/ZNoFctxVbTqvO91QmqmltaRaCqM4BIEUnxOCy/RCQS54b6d1X9p59d6sz3cqxrqUvfSylVzQHmAAMrbKrRe1goJYiFQEcRaSciUTgNONMq7DMNuMldvhr4l7qtPUHmmNdSoT54KE7da100DbjRfWqmD7BPVbd7HdSJEJFmpfXBItIb5/+/oPsB4sb4FrBaVf9ayW514nupzrXUoe8lVUQaussxwEXAmgq71eg9LOJEP1jXqGqRiNwBzMJ5Cmicqq4UkceBRao6Decf0gQRWYfT2DjCu4grV81r+Z2IDAWKcK5ltGcBV0FEJuE8RZIiIpnAIziNb6jqq8AMnCdm1gH5wM3eRHps1biWq4HbRaQIOAiMCNIfIP2AG4Af3PpugP8FWkOd+16qcy115XtpDowXkXCcJPaeqn4SyHuYDbVhjDHGr1CqYjLGGHMcLEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL8sQRhzHESk2GfUz6XiZyTdkzh228pGgjXGCyHTD8KYGnLQHerAmHrPShDG1AAR2SQiz4jID+6Y/ae469uKyL/cQRO/FJHW7vqmIvKhO0DcMhHp6x4qXETecMf7n+32mDXGE5YgjDk+MRWqmK712bZPVbsCLwHPu+teBMa7gyb+HRjrrh8LzHUHiDsDWOmu7wi8rKqdgRzgqgBfjzGVsp7UxhwHEclT1Xg/6zcB56vqBndwuB2q2lhEdgPNVfWwu367qqaISBbQ0mdAxdLhqD9X1Y7u+/uASFV9IvBXZszRrARhTM3RSpaPR6HPcjHWTmg8ZAnCmJpzrc9/57vL33JkwLTrga/d5S+B26FsEpik2grSmOqyXyfGHJ8Yn1FBAWaqaumjrskishynFDDSXXcn8LaI3AtkcWTU07uA10XkVpySwu1A0A2XbUKbtUEYUwPcNogMVd3tdSzG1BSrYjLGGOOXlSCMMcb4ZSUIY4wxflmCMMYY45clCGOMMX5ZgjDGGOOXJQhjjDF+/T9+EBQwA7fD6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_loss_history, label='train loss')\n",
    "plt.plot(test_loss_history, label='test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(' train and test MSE Loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1671680740232,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "cbj2v5gy5z-M",
    "outputId": "ca48ca06-d4d8-48de-ab66-6266e8225e34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7bc84e5c70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the train and test rho\n",
    "plt.plot(train_rho_history, label='train rho')\n",
    "plt.plot(test_rho_history, label='test rho')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('rho')\n",
    "plt.title(' train and test rho')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZEs_K1mNFAn"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPtqnWy1xHdr"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_mutations.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1671711725930,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "0xpw5eUIxK8F"
   },
   "outputs": [],
   "source": [
    "# add spaces betwwen Amnino acids letter to tokenize\n",
    "def add_spaces(x):\n",
    "    return \" \".join(list(x))\n",
    "\n",
    "test.protSeq1 = test.protSeq1.apply(add_spaces)\n",
    "test.protSeq2 = test.protSeq2.apply(add_spaces)\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 21338,
     "status": "ok",
     "timestamp": 1671716211455,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "uixWkrtyr3iM"
   },
   "outputs": [],
   "source": [
    "# load torch model\n",
    "model = torch.load(SAVE_PATH+f'prot_{VER}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1799,
     "status": "ok",
     "timestamp": 1671716213244,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "USZufcLGxRML"
   },
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(SAVE_PATH+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1671716213244,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "PTCdxkoZxUpj"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self,tokenizer, df):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs1 = df['protSeq1'].values\n",
    "        self.inputs2 = df['protSeq2'].values\n",
    "        self.position = df['position'].values\n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        inputs1 = prepare_input(self.tokenizer, self.inputs1[item])\n",
    "        inputs2 = prepare_input(self.tokenizer, self.inputs2[item])\n",
    "        # do one hot encoding of position \n",
    "        position = np.zeros(MAX_LEN)\n",
    "        position[self.position[item]] = 1\n",
    "        position = torch.tensor(position, dtype=torch.int8)\n",
    "       \n",
    " \n",
    "        return inputs1, inputs2, position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1671716218033,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "13G49g6nz1PI"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1671717325883,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "ISNVYXJpxVkr"
   },
   "outputs": [],
   "source": [
    "def predict(model,test_loader):\n",
    "    model = model.eval()\n",
    "    preds = []\n",
    "   \n",
    "    for batch_idx, (inputs1, inputs2, position ) in enumerate(tqdm.tqdm(test_loader)):\n",
    "          # inputs to device\n",
    "        for k, v in inputs1.items():\n",
    "            inputs1[k] = v.to(device)     \n",
    "        for k, v in inputs2.items():\n",
    "            inputs2[k] = v.to(device)\n",
    "        position = position.to(device)\n",
    "         \n",
    "        \n",
    "      \n",
    "        # predict\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs1,inputs2,position)\n",
    "            preds.append(output.cpu().numpy())\n",
    "\n",
    "          \n",
    "        #bug fix with shape of last output\n",
    "        predictions = np.concatenate(preds[:-1])\n",
    "        predcitions = np.concatenate([preditions,preds[-1].reshape(1)]) \n",
    "            \n",
    "   \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1671717326321,
     "user": {
      "displayName": "Hichem Hadhri",
      "userId": "12616591780675551937"
     },
     "user_tz": -60
    },
    "id": "8J6lSmUtxZfs"
   },
   "outputs": [],
   "source": [
    "test['target'] = 0  # placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bk3wAwh1xf4e",
    "outputId": "ac5dbd4c-f1b2-4e1c-9480-da3e5c3cdf08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/403 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/403 [00:01<09:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/403 [00:02<09:28,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/403 [00:04<09:23,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/403 [00:05<09:20,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/403 [00:07<09:20,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 6/403 [00:08<09:20,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 7/403 [00:09<09:18,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 8/403 [00:11<09:16,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 9/403 [00:12<09:15,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 10/403 [00:14<09:13,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 11/403 [00:15<09:12,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 12/403 [00:16<09:11,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 13/403 [00:18<09:10,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 14/403 [00:19<09:09,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 15/403 [00:21<09:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 16/403 [00:22<09:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 17/403 [00:24<09:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 18/403 [00:25<09:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 19/403 [00:26<09:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 20/403 [00:28<09:06,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 21/403 [00:29<09:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 22/403 [00:31<09:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 23/403 [00:32<09:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 24/403 [00:34<09:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 25/403 [00:35<09:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 26/403 [00:36<09:03,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 27/403 [00:38<09:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 28/403 [00:40<09:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 29/403 [00:41<09:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 30/403 [00:42<09:08,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 31/403 [00:44<09:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 32/403 [00:45<09:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 33/403 [00:47<09:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 34/403 [00:48<09:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 35/403 [00:50<09:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 36/403 [00:51<08:59,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 37/403 [00:53<08:58,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 38/403 [00:54<08:57,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 39/403 [00:56<08:56,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 40/403 [00:57<08:55,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 41/403 [00:59<08:54,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 42/403 [01:00<08:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 43/403 [01:02<08:51,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 44/403 [01:03<08:50,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 45/403 [01:05<08:47,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 46/403 [01:06<08:45,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 47/403 [01:07<08:44,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 48/403 [01:09<08:41,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 49/403 [01:10<08:39,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 50/403 [01:12<08:37,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 51/403 [01:13<08:34,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 52/403 [01:15<08:32,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 53/403 [01:16<08:30,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 54/403 [01:18<08:28,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–Ž        | 55/403 [01:19<08:25,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 56/403 [01:21<08:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 57/403 [01:22<08:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 58/403 [01:24<08:22,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 59/403 [01:25<08:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 60/403 [01:26<08:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 61/403 [01:28<08:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 62/403 [01:29<08:13,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 63/403 [01:31<08:11,  1.44s/it]"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(tokenizer,test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "preds = predict(model,test_loader)\n",
    "\n",
    "\n",
    "\n",
    "test['target'] = preds\n",
    "\n",
    "#groupb by group1 and group2 and take the mean of the target\n",
    "mean = test.groupby(['operation']).mean()['target']['replace']\n",
    "\n",
    "test['target'] = test.apply(lambda row : mean if row['operation'] == 'delete' else row['target'], axis=1)\n",
    "\n",
    "submission['tm'] = test['target'].values\n",
    "\n",
    "\n",
    "submission.to_csv('submissions/submission_prot.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0H4NovfGvda"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
